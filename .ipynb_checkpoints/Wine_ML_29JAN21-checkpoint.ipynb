{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies (packages and modules)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data set into jupyter notebook\n",
    "The endstate is a dataframe containing a label column and text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93557 entries, 0 to 93556\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   country             93557 non-null  object \n",
      " 1   province            93557 non-null  object \n",
      " 2   region_1            93557 non-null  object \n",
      " 3   winery              93557 non-null  object \n",
      " 4   wine_type           93557 non-null  object \n",
      " 5   wine_style          93557 non-null  object \n",
      " 6   variety             93557 non-null  object \n",
      " 7   name                93557 non-null  object \n",
      " 8   points              93557 non-null  int64  \n",
      " 9   price               93557 non-null  float64\n",
      " 10  points_earned       93557 non-null  int64  \n",
      " 11  value_points_per_$  93557 non-null  float64\n",
      " 12  description         93557 non-null  object \n",
      "dtypes: float64(2), int64(2), object(9)\n",
      "memory usage: 9.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# get csv file from AWS S3 bucket\n",
    "url =\"https://wine-demo-bucket.s3.amazonaws.com/wine_matched_final.csv\"\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93557 entries, 0 to 93556\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   wine_type    93557 non-null  object\n",
      " 1   description  93557 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# reduce the dataframe to just wine_type and description\n",
    "# this is going to be our 'label' and 'text' columns (in the cell below)\n",
    "column_names = ['wine_type', 'description']\n",
    "df = df.reindex(columns=column_names)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93557 entries, 0 to 93556\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   93557 non-null  object\n",
      " 1   text    93557 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# rename wine type to 'label' and description to 'text'\n",
    "df.rename(columns={\"wine_type\": 'label', \"description\": 'text'}, inplace=True)\n",
    "data = df\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Red_wine      56925\n",
       "White_wine    32859\n",
       "Other_wine     3773\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many of each wine_type are in our wine_description dataframe?\n",
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Mac Watson honors the memory of a wine once ma...\n",
       "1    This spent 20 months in 30% new French oak, an...\n",
       "2    This re-named vineyard was formerly bottled as...\n",
       "3    The producer sources from two blocks of the vi...\n",
       "4    From 18-year-old vines, this supple well-balan...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Devide the data into train and test using sklearn train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text'] # the description\n",
    "y = data['label'] # the wine type\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract features by tokenizing text using the bag of words technique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will tokenize and filter stop words using CountVectorizer\n",
    "# this will be used to build a dictionary of features and transforms documents to feature vectors:\n",
    "count_vect = CountVectorizer()\n",
    "count_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70167, 22291)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating bag of words for training data\n",
    "# Here by doing ‘count_vect.fit_transform()’\n",
    "# we are learning the vocabulary dictionary and it returns a Document-Term matrix. [n_samples, n_features].\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer supports counts of N-grams of words or consecutive characters. Once fitted, the vectorizer has built a dictionary of feature indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer supports counts of N-grams of words or consecutive characters. Once fitted, the vectorizer has built a dictionary of feature indices:\n",
    "count_vect.vocabulary_.get(u'algorithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From occurrences to frequencies\n",
    "From occurrences to frequencies¶Occurrence count is a good start but there is an issue: longer documents will have higher average count values than shorter documents, even though they might talk about the same topics.\n",
    "\n",
    "#### TF - Term Frequencies#### TF - Term Frequencies\n",
    "To avoid these potential discrepancies it suffices to divide the number of occurrences of each word in a document by the total number of words in the document: these new features are called tf for Term Frequencies.\n",
    "\n",
    "#### TF - IDF (Term Frequency times inverse document frequency)#### TF - IDF (Term Frequency times inverse document frequency)\n",
    "Another refinement on top of tf is to downscale weights for words that occur in many documents in the corpus and are therefore less informative than those that occur only in a smaller portion of the corpus.\n",
    "\n",
    "This downscaling is called tf–idf for “Term Frequency times Inverse Document Frequency”.\n",
    "\n",
    "Both tf and tf–idf can be computed as follows using TfidfTransformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70167, 22291)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for our calculations we need to calculate TF and TF-IDF\n",
    "# We can achieve both using below line of code and the X_train_counts from above:\n",
    "\n",
    "tfidf_transformer = TfidfTransformer(use_idf=False)\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape\n",
    "\n",
    "# The output will be the dimension of the Document-Term matrix -> (11314, 130107) which is the same shape as our X_train_counts shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a Classifier on the X_train_tfidf and y_train data\n",
    "Naive Bayes Classifier: the one most suitable for word counts is the multinomial variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import MultinomialNB - this was done under dependencies in cell [1]\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After fitting the training set, let’s make a prediction using the first row of X_test and y_test.\n",
    "\n",
    "To try to predict the outcome on a new document we need to extract the features using almost the same feature extracting chain as before. The difference is that we call transform instead of fit_transform on the transformers, since they have already been fit to the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['While there are plenty of firm tannins and weight here, the wine does feel somewhat hollow. The red fruits are there, showing slowly against the tannins. It has fine final acidity, but not the power and concentration you should expect.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are going to want the text from a row (take first row) of X_test\n",
    "new_description = [X_test.iloc[0]]\n",
    "\n",
    "new_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Red_wine'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we enter this into a prediction it should produce the y_test.iloc[0] category\n",
    "y_test.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Build a pipeline\n",
    "In order to make the vectorizer => transformer => classifier easier to work with, scikit-learn provides a Pipeline class that behaves like a compound classifier:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the following\n",
    "# The names vect, tfidf and clf (classifier) are arbitrary. \n",
    "# We will use them to perform grid search for suitable hyperparameters below. \n",
    "# We can now train the model with a single command:\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation of the performance on the test set\n",
    "Evaluating the predictive accuracy of the model is equally easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9452846927541498"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#>>> docs_test = twenty_test.data\n",
    "#>>> predicted = text_clf.predict(docs_test)\n",
    "#>>> np.mean(predicted == twenty_test.target)\n",
    "#0.8348...\n",
    "\n",
    "docs_test = data['text']\n",
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == data['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieved 94.5% accuracy. Let’s see if we can do better with a linear support vector machine (SVM), which is widely regarded as one of the best text classification algorithms (although it’s also a bit slower than naïve Bayes). We can change the learner by simply plugging a different classifier object into our pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', SGDClassifier())])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using Support Vector Machine classifier with Stochastic gradient descent (SGD) learning\n",
    "\n",
    "text_clf = Pipeline ([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier())\n",
    "])\n",
    "\n",
    "text_clf.fit(data['text'], data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9660314033156258"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = text_clf.predict(data['text'])\n",
    "np.mean(predicted == data['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieved 96.6% accuracy using the SVM. scikit-learn provides further utilities for more detailed performance analysis of the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Other_wine       0.86      0.41      0.56      3773\n",
      "    Red_wine       0.97      0.99      0.98     56925\n",
      "  White_wine       0.97      0.99      0.98     32859\n",
      "\n",
      "    accuracy                           0.97     93557\n",
      "   macro avg       0.93      0.80      0.84     93557\n",
      "weighted avg       0.96      0.97      0.96     93557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(data['label'], predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1561,  1428,   784],\n",
       "       [  236, 56366,   323],\n",
       "       [   24,   383, 32452]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(data['label'], predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
